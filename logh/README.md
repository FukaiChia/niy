logh: A New Activation Function That Looks Like "tanh"   
====
logh is desiged to remove the vanishing gradient problem of tanh/sigmoid

